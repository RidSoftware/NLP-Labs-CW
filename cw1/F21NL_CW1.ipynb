{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 (Enviroment Setup)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Importing the Datasets\n",
        "wikitext (*full* ) - 859955 docs\n",
        "\n",
        "wikitext (*small* ) - 10000 docs"
      ],
      "metadata": {
        "id": "I02HtuGWggmv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQaGMPUu5vQW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf766ca-8ad3-4a28-900c-95365034b453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-09 20:07:43--  https://www.dropbox.com/scl/fi/ibd4cmixckghx6hhb361c/wikitext-filtered-full.zip?rlkey=q71cebf0k5fvvwhmcntoswzhq&dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.18, 2620:100:6057:18::a27d:d12\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uccff996ba72a552ce0d939aa523.dl-eu.dropboxusercontent.com/cd/0/inline/Cy7aPsq_UKgH1asNm1c4qbSLSVf2FTGyLqDSEnoH6r44ymsGIrxIP5scDY_7C6KxGNL-psklCEUNODEH34FCBKD5NlUJfc-o2DAIFwV3OFf0tc57V8Gfu-IKgtFzvqaxsZ9lwrDeGkYSh5b0Gg785pBq/file?dl=1# [following]\n",
            "--2025-10-09 20:07:44--  https://uccff996ba72a552ce0d939aa523.dl-eu.dropboxusercontent.com/cd/0/inline/Cy7aPsq_UKgH1asNm1c4qbSLSVf2FTGyLqDSEnoH6r44ymsGIrxIP5scDY_7C6KxGNL-psklCEUNODEH34FCBKD5NlUJfc-o2DAIFwV3OFf0tc57V8Gfu-IKgtFzvqaxsZ9lwrDeGkYSh5b0Gg785pBq/file?dl=1\n",
            "Resolving uccff996ba72a552ce0d939aa523.dl-eu.dropboxusercontent.com (uccff996ba72a552ce0d939aa523.dl-eu.dropboxusercontent.com)... 162.125.70.15, 2620:100:6028:15::a27d:470f\n",
            "Connecting to uccff996ba72a552ce0d939aa523.dl-eu.dropboxusercontent.com (uccff996ba72a552ce0d939aa523.dl-eu.dropboxusercontent.com)|162.125.70.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Cy7dDAkCN3Iyth5o6Z2pk9rxILzBuARLpId05hTkl3Mpf0K3zTMxWt3Z_hCmVrR2LZ8r4JJ7N0Yuy3ktmU1CKTlkdO8smMU4hkVM6gWsZETekOGwX08FUoV_-nrXz9iUSzru9qQoiFe7DMTsPF5uw2In9VKZvwEaeNvcmW1VKsf_nIl3aPgSjCVdyNffiCuBqCS7XFZ2yGFNgDNGbWWDIPm03TRSBHhcdhk_RNEWtOF5hZeszl-UU94Lponj6MSSo6GWQmg-PVwxcnFfKFJ-0-vRNxItK2kbHKA8LGES1U_LE6IaE5teAXN2tEHcmtJ9gn_TS7agFchz3sGbLlt_oCFxZJkcfaAQnaBM0mPSX9-myRnFNmo_UK-lNh8vS4KQXGg/file?dl=1 [following]\n",
            "--2025-10-09 20:07:46--  https://uccff996ba72a552ce0d939aa523.dl-eu.dropboxusercontent.com/cd/0/inline2/Cy7dDAkCN3Iyth5o6Z2pk9rxILzBuARLpId05hTkl3Mpf0K3zTMxWt3Z_hCmVrR2LZ8r4JJ7N0Yuy3ktmU1CKTlkdO8smMU4hkVM6gWsZETekOGwX08FUoV_-nrXz9iUSzru9qQoiFe7DMTsPF5uw2In9VKZvwEaeNvcmW1VKsf_nIl3aPgSjCVdyNffiCuBqCS7XFZ2yGFNgDNGbWWDIPm03TRSBHhcdhk_RNEWtOF5hZeszl-UU94Lponj6MSSo6GWQmg-PVwxcnFfKFJ-0-vRNxItK2kbHKA8LGES1U_LE6IaE5teAXN2tEHcmtJ9gn_TS7agFchz3sGbLlt_oCFxZJkcfaAQnaBM0mPSX9-myRnFNmo_UK-lNh8vS4KQXGg/file?dl=1\n",
            "Reusing existing connection to uccff996ba72a552ce0d939aa523.dl-eu.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 191859755 (183M) [application/binary]\n",
            "Saving to: ‘wikitext-filtered-full.zip’\n",
            "\n",
            "wikitext-filtered-f 100%[===================>] 182.97M  26.6MB/s    in 8.0s    \n",
            "\n",
            "2025-10-09 20:07:54 (23.0 MB/s) - ‘wikitext-filtered-full.zip’ saved [191859755/191859755]\n",
            "\n",
            "--2025-10-09 20:07:54--  https://www.dropbox.com/scl/fi/ek174r3sg7qjx0aa9atop/wikitext-filtered-10k.zip?rlkey=zy6jqxv6qsc16lr9qm3ki9uhf&dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6028:18::a27d:4712\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc47c47cf2f8a886c93c221f5e44.dl-eu.dropboxusercontent.com/cd/0/inline/Cy6ZNrMh0RElYQM8eSLZkzAg3x_-2jH_E6ixkOzaPBc-y0p7P3F2EKUlUEQZPdj1MCIwr-1Tmsl8anBlIBdfTQ97PlATChyo8aMJnHhpg1-29EQqebyju56TS7o-a8GjBlyEfjNsKNTTwjh_YUKe48Wx/file?dl=1# [following]\n",
            "--2025-10-09 20:07:55--  https://uc47c47cf2f8a886c93c221f5e44.dl-eu.dropboxusercontent.com/cd/0/inline/Cy6ZNrMh0RElYQM8eSLZkzAg3x_-2jH_E6ixkOzaPBc-y0p7P3F2EKUlUEQZPdj1MCIwr-1Tmsl8anBlIBdfTQ97PlATChyo8aMJnHhpg1-29EQqebyju56TS7o-a8GjBlyEfjNsKNTTwjh_YUKe48Wx/file?dl=1\n",
            "Resolving uc47c47cf2f8a886c93c221f5e44.dl-eu.dropboxusercontent.com (uc47c47cf2f8a886c93c221f5e44.dl-eu.dropboxusercontent.com)... 162.125.70.15, 2620:100:6057:15::a27d:d0f\n",
            "Connecting to uc47c47cf2f8a886c93c221f5e44.dl-eu.dropboxusercontent.com (uc47c47cf2f8a886c93c221f5e44.dl-eu.dropboxusercontent.com)|162.125.70.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Cy5WM04MbzadRRDyzLjye293ZWjSvH1Y9NQJZOmVO_pmg9cFinBlp8PhsFqFdqKNjFeBZ_SsXsT9c7_bU46BhdMXsrUsO3pdM2-BObqU7wgwsn18J_Cvsu9vC6B9kPj6ySfsO1szPmQAA3G15uZF1ihZ3CB0lHTEzSyRX08XEI2mQHd3mm3vjCUcH2WVvWJl0T4h2I4ICarEvW8vwVs8tqQ52cftwehJoe9GfSc8gNt_dWa7bdVDezT1bfNBXZFXQRgpwUB6wy3gVVR47EoR2AH6rekUsR5zXp-N4t_zFfSMU8U4Ce0RQYfIHbXKgaa-2bCg_ZCntuKmuHWoSJqeS4j6Gl10CWOtSO_atwhrGHfgcNDSYlkFpzbKTbTzNL4Ye7s/file?dl=1 [following]\n",
            "--2025-10-09 20:07:56--  https://uc47c47cf2f8a886c93c221f5e44.dl-eu.dropboxusercontent.com/cd/0/inline2/Cy5WM04MbzadRRDyzLjye293ZWjSvH1Y9NQJZOmVO_pmg9cFinBlp8PhsFqFdqKNjFeBZ_SsXsT9c7_bU46BhdMXsrUsO3pdM2-BObqU7wgwsn18J_Cvsu9vC6B9kPj6ySfsO1szPmQAA3G15uZF1ihZ3CB0lHTEzSyRX08XEI2mQHd3mm3vjCUcH2WVvWJl0T4h2I4ICarEvW8vwVs8tqQ52cftwehJoe9GfSc8gNt_dWa7bdVDezT1bfNBXZFXQRgpwUB6wy3gVVR47EoR2AH6rekUsR5zXp-N4t_zFfSMU8U4Ce0RQYfIHbXKgaa-2bCg_ZCntuKmuHWoSJqeS4j6Gl10CWOtSO_atwhrGHfgcNDSYlkFpzbKTbTzNL4Ye7s/file?dl=1\n",
            "Reusing existing connection to uc47c47cf2f8a886c93c221f5e44.dl-eu.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2230160 (2.1M) [application/binary]\n",
            "Saving to: ‘wikitext-filtered-10k.zip’\n",
            "\n",
            "wikitext-filtered-1 100%[===================>]   2.13M  1.99MB/s    in 1.1s    \n",
            "\n",
            "2025-10-09 20:07:58 (1.99 MB/s) - ‘wikitext-filtered-10k.zip’ saved [2230160/2230160]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O wikitext-filtered-full.zip \"https://www.dropbox.com/scl/fi/ibd4cmixckghx6hhb361c/wikitext-filtered-full.zip?rlkey=q71cebf0k5fvvwhmcntoswzhq&dl=1\"\n",
        "!wget -O wikitext-filtered-10k.zip \"https://www.dropbox.com/scl/fi/ek174r3sg7qjx0aa9atop/wikitext-filtered-10k.zip?rlkey=zy6jqxv6qsc16lr9qm3ki9uhf&dl=1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GgyhgwO59KU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408eab3c-b80b-4d52-efd3-620e80662b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  wikitext-filtered-full.zip\n",
            "   creating: wikitext-filtered-full/\n",
            "  inflating: wikitext-filtered-full/dataset_info.json  \n",
            "  inflating: wikitext-filtered-full/state.json  \n",
            "  inflating: wikitext-filtered-full/data-00000-of-00001.arrow  \n",
            "Archive:  wikitext-filtered-10k.zip\n",
            "   creating: wikitext-filtered-10k/\n",
            "  inflating: wikitext-filtered-10k/dataset_info.json  \n",
            "  inflating: wikitext-filtered-10k/state.json  \n",
            "  inflating: wikitext-filtered-10k/data-00000-of-00001.arrow  \n"
          ]
        }
      ],
      "source": [
        "!unzip wikitext-filtered-full.zip\n",
        "!unzip wikitext-filtered-10k.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbUoBOOH5_Zy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d511fc6f-67aa-4914-942e-0bbb2a279fdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# datasets package provides dataset tools from hugginface\n",
        "!pip install datasets\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aYe6Rq5k6Bgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c925d93-c747-40a4-a08f-4ef912c0c810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wikitext_small: 10000 docs, wikitext_large: 859955 docs\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "def load_dataset():\n",
        "  wikitext_small = \"wikitext-filtered-10k\"\n",
        "  wikitext_large = \"wikitext-filtered-full\"\n",
        "\n",
        "  dataset_small = Dataset.load_from_disk(wikitext_small)\n",
        "  dataset_large = Dataset.load_from_disk(wikitext_large)\n",
        "  print(\"wikitext_small: {} docs, wikitext_large: {} docs\".format(len(dataset_small), len(dataset_large)))\n",
        "  return dataset_small, dataset_large\n",
        "\n",
        "wikitext_small, wikitext_large = load_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding the Dataset\n",
        "Summary statistics"
      ],
      "metadata": {
        "id": "gAUcAjXfgIFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wt = wikitext_small\n",
        "#wt = wikitext_large\n",
        "\n",
        "print('# TYPE OF THE DATASET:', '\\n', type(wt))\n",
        "print(wt, '\\n')\n",
        "print('# ENTRIES LOOK LIKE:')\n",
        "print(wt.features, '\\n', wt[0], '\\n', wt[1], '\\n')\n",
        "\n",
        "print('# DATASET STATISTICS:')\n",
        "print('No. of docs:', len(wt))\n",
        "lengths = [len(doc['text'].split()) for doc in wt]\n",
        "print('Mean doc length:', sum(lengths)/len(lengths), 'words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di-0S5z9d9NE",
        "outputId": "22cb1543-6fd0-411b-9140-2670d50a2670"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# TYPE OF THE DATASET: \n",
            " <class 'datasets.arrow_dataset.Dataset'>\n",
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 10000\n",
            "}) \n",
            "\n",
            "# ENTRIES LOOK LIKE:\n",
            "{'text': Value('string')} \n",
            " {'text': 'Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" .'} \n",
            " {'text': \"The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n .\"} \n",
            "\n",
            "# DATASET STATISTICS:\n",
            "No. of docs: 10000\n",
            "Mean doc length: 115.0954 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 (Train Baselines)\n",
        "\n",
        "---\n",
        "Installing dependancies\n",
        "- gensim - word2vec models\n",
        "- nltk (natural language tool kit) - stopwords removal"
      ],
      "metadata": {
        "id": "fUWa02Kzq3YT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim nltk\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "metadata": {
        "id": "5490qFGSwT7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_dataset(dataset):\n",
        "    text_col = 'text' if 'text' in dataset.column_names else dataset.column_names[0]\n",
        "    tokenized = []\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "        text = dataset[i][text_col]\n",
        "        if not isinstance(text, str):\n",
        "            continue\n",
        "        tokens = [t.lower() for t in text.split() if t.isalpha() and t.lower() not in stop_words]\n",
        "        if tokens:\n",
        "            tokenized.append(tokens)\n",
        "\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "ZMphBXL8nRVE",
        "outputId": "42fbc6f4-0d62-4cc5-c914-b83de4a9f98f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_small = preprocess_dataset(wikitext_small)\n",
        "#tokens_large = preprocess_dataset(wikitext_large)"
      ],
      "metadata": {
        "id": "f8tNPp7Jwb-i"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_word2vec(tokens, model_name, vector_size=50, window=5, min_count=5, epochs=5):\n",
        "    print(f\"Training {model_name} ...\")\n",
        "    model = Word2Vec(\n",
        "        sentences=tokens,\n",
        "        vector_size=vector_size,\n",
        "        window=window,\n",
        "        min_count=min_count,\n",
        "        epochs=epochs\n",
        "    )\n",
        "    model.save(f\"{model_name}.model\")\n",
        "    model.wv.save(f\"{model_name}.kv\")\n",
        "    print(f\"{model_name} saved.\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "vF6w1eeL6xJW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_small = train_word2vec(tokens_small, \"word2vec_small\")\n",
        "#model_large = train_word2vec(tokens_large, \"word2vec_large\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMgpuHkuwn0E",
        "outputId": "00815a27-c57d-47b1-e722-3ceaee92afa9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training word2vec_small ...\n",
            "word2vec_small saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(model_small.wv)\n",
        "print(f\"Vocab size (learned by model):\", vocab_size, '\\n')\n",
        "\n",
        "example_tokens = ['king', 'queen', 'doctor', 'nurse', 'city', 'country']\n",
        "for token in example_tokens:\n",
        "    if token in model_small.wv:\n",
        "        print(f\"Top-5 similar to '{token}':\", model_small.wv.most_similar(token, topn=10))\n",
        "    else:\n",
        "        print(f\"'{token}' not in vocabulary.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H9TVBpxxGTo",
        "outputId": "9eefc2be-3856-4df9-d9ab-8fe8586ddee7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size (learned by model): 13838 \n",
            "\n",
            "Top-5 similar to 'king': [('polish', 0.9674179553985596), ('god', 0.9640176892280579), ('william', 0.9638584852218628), ('yat', 0.9628190994262695), ('gods', 0.9623178243637085), ('political', 0.9621992111206055), ('empire', 0.9621983170509338), ('holy', 0.9617152214050293), ('great', 0.9606372714042664), ('father', 0.9599580764770508)]\n",
            "Top-5 similar to 'queen': [('henry', 0.9973913431167603), ('emperor', 0.9958850741386414), ('k', 0.9954298734664917), ('raymond', 0.9949839115142822), ('throne', 0.99497389793396), ('assyrian', 0.994867205619812), ('sought', 0.9948545098304749), ('warfare', 0.9947125911712646), ('sir', 0.9947078824043274), ('egypt', 0.994704008102417)]\n",
            "Top-5 similar to 'doctor': [('veronica', 0.9986439943313599), ('results', 0.9985044598579407), ('caught', 0.9984821081161499), ('discussed', 0.9983595013618469), ('responded', 0.9982613921165466), ('fall', 0.9980997443199158), ('chose', 0.9979474544525146), ('article', 0.9979352355003357), ('attracted', 0.9979070425033569), ('showed', 0.9978888034820557)]\n",
            "Top-5 similar to 'nurse': [('shark', 0.9988310933113098), ('effect', 0.9987406730651855), ('tawny', 0.9986280202865601), ('attributed', 0.9984596371650696), ('requires', 0.9983562231063843), ('weapon', 0.9980946779251099), ('reaction', 0.9980827569961548), ('moon', 0.9980485439300537), ('oxygen', 0.9980310201644897), ('behavior', 0.9979782104492188)]\n",
            "Top-5 similar to 'city': [('state', 0.9559193253517151), ('county', 0.9292951822280884), ('national', 0.9070938229560852), ('moved', 0.8929959535598755), ('town', 0.8914775848388672), ('mackinaw', 0.8860195279121399), ('route', 0.8855055570602417), ('africa', 0.8796854615211487), ('southern', 0.8788232207298279), ('carolina', 0.8772608637809753)]\n",
            "Top-5 similar to 'country': [('belgium', 0.9888278245925903), ('official', 0.9881771802902222), ('toured', 0.9877164363861084), ('shipments', 0.9871306419372559), ('dated', 0.9870644211769104), ('network', 0.9850134253501892), ('denoting', 0.9842528700828552), ('promotional', 0.9831187129020691), ('countries', 0.9830328226089478), ('usa', 0.982700765132904)]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "athnlp-lab3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}